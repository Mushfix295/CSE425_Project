# -*- coding: utf-8 -*-
"""22301278_425_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o8wYp7SaLu5cSm4ohBA9UhO4JfUByPMJ
"""

# -*- coding: utf-8 -*-
"""
Code 1: Deterministic Baseline - Standard Autoencoder
"""

# Install necessary libraries
!pip install -q scikit-learn matplotlib

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, TensorDataset
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.preprocessing import normalize
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import numpy as np

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")


# --- Data Loading using Torchvision (The Reliable Way) ---
print("Loading MNIST dataset using torchvision...")

# Define the transformation to normalize data to [-1, 1]
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Download and load the training data
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)

# Extract images and labels into tensors. The transform is already applied here.
images = []
for img, label in trainset:
    images.append(img)
labels = trainset.targets

images = torch.stack(images)

print(f"Dataset loaded. Image tensor shape: {images.shape}")


# --- Model Architecture ---
class Autoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 512),
            nn.ReLU(),
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.Linear(128, 32)
        )
        self.decoder = nn.Sequential(
            nn.Linear(32, 128),
            nn.ReLU(),
            nn.Linear(128, 512),
            nn.ReLU(),
            nn.Linear(512, 784),
            nn.Tanh() # Tanh matches the [-1, 1] normalization
        )
    def forward(self, x):
        z = self.encoder(x)
        out = self.decoder(z)
        return out

# --- Training ---
model = Autoencoder().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.MSELoss()
# Flatten the images for the DataLoader
loader = DataLoader(TensorDataset(images.view(-1, 784)), batch_size=256, shuffle=True)

print("\nStarting Standard Autoencoder training...")
for epoch in range(20):
    total_loss = 0
    model.train()
    for data in loader:

        # We extract the tensor from the 'data' list before moving it to the device
        img_batch = data[0].to(device)

        out = model(img_batch)
        loss = criterion(out, img_batch)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"[Epoch {epoch+1}] Autoencoder Loss: {total_loss / len(loader):.4f}")

# --- Evaluation ---
print("\nEvaluating clustering performance...")
model.eval()
with torch.no_grad():
    embeddings = model.encoder(images.view(-1, 784).to(device)).cpu().numpy()

normalized = normalize(embeddings)
preds = KMeans(n_clusters=10, n_init=30, random_state=42).fit_predict(normalized)

sil_score = silhouette_score(normalized, preds)
dbi = davies_bouldin_score(normalized, preds)
chi = calinski_harabasz_score(normalized, preds)

print("\nðŸ“Š Autoencoder Clustering Metrics:")
print(f"Silhouette Score:           {sil_score:.4f}")
print(f"Davies-Bouldin Index:       {dbi:.4f}")
print(f"Calinski-Harabasz Index:    {chi:.2f}")

# --- Visualization ---
print("\nGenerating t-SNE plot...")
subset = 2000
idx = np.random.choice(len(normalized), subset, replace=False)
tsne = TSNE(n_components=2, random_state=42)
reduced = tsne.fit_transform(normalized[idx])

plt.figure(figsize=(8,6))
plt.scatter(reduced[:,0], reduced[:,1], c=labels[idx], cmap="tab10", s=10)
plt.title("Autoencoder Embedding Clusters (t-SNE)")
plt.xlabel("Dim 1")
plt.ylabel("Dim 2")
plt.show()

# -*- coding: utf-8 -*-
"""
Code 2: Non-Deterministic Model - Variational Autoencoder

"""

# Install necessary libraries if not already installed
!pip install -q scikit-learn matplotlib

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, TensorDataset
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.preprocessing import normalize
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import numpy as np

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")


# --- Data Loading using Torchvision (The Reliable Way) ---
print("Loading MNIST dataset using torchvision...")

# Define the transformation to normalize data to [-1, 1]
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Download and load the training data
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)

# Extract images and labels into tensors
images = []
for img, label in trainset:
    images.append(img)
labels = trainset.targets

images = torch.stack(images)

print(f"Dataset loaded. Image tensor shape: {images.shape}")


# --- Model Architecture ---
class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=512, latent_dim=32):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 256),
            nn.ReLU()
        )
        self.fc_mu = nn.Linear(256, latent_dim)
        self.fc_logvar = nn.Linear(256, latent_dim)
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.ReLU(),
            nn.Linear(256, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
            nn.Tanh()
        )
    def encode(self, x):
        h = self.encoder(x)
        return self.fc_mu(h), self.fc_logvar(h)
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    def decode(self, z):
        return self.decoder(z)
    def forward(self, x):
        mu, logvar = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

# --- Loss Function ---
def vae_loss_function(recon_x, x, mu, logvar):
    recon_loss = F.mse_loss(recon_x, x.view(-1, 784), reduction='sum')
    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return recon_loss + kld_loss

# --- Training ---
vae_model = VAE().to(device)
optimizer = optim.Adam(vae_model.parameters(), lr=1e-3)
train_loader = DataLoader(TensorDataset(images), batch_size=256, shuffle=True)

print("\nStarting VAE training...")
for epoch in range(20):
    vae_model.train()
    total_loss = 0
    for batch in train_loader:
        batch_x = batch[0].to(device)
        optimizer.zero_grad()
        recon_batch, mu, logvar = vae_model(batch_x)
        loss = vae_loss_function(recon_batch, batch_x, mu, logvar)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"[Epoch {epoch+1}] VAE Avg Loss: {total_loss / len(train_loader.dataset):.4f}")

# --- Evaluation ---
print("\nEvaluating clustering performance...")
vae_model.eval()
with torch.no_grad():
    mu_embeddings, _ = vae_model.encode(images.view(-1, 784).to(device))
    mu_embeddings = mu_embeddings.cpu().numpy()

normalized_embeddings = normalize(mu_embeddings)
cluster_preds = KMeans(n_clusters=10, n_init=30, random_state=42).fit_predict(normalized_embeddings)

sil_score = silhouette_score(normalized_embeddings, cluster_preds)
dbi = davies_bouldin_score(normalized_embeddings, cluster_preds)
chi = calinski_harabasz_score(normalized_embeddings, cluster_preds)

print("\nðŸ“Š VAE Clustering Metrics:")
print(f"Silhouette Score:           {sil_score:.4f}")
print(f"Davies-Bouldin Index:       {dbi:.4f}")
print(f"Calinski-Harabasz Index:    {chi:.2f}")

# --- Visualizations ---
# 1. t-SNE Plot
print("\nGenerating t-SNE plot...")
subset = 2000
idx = np.random.choice(len(normalized_embeddings), subset, replace=False)
tsne = TSNE(n_components=2, random_state=42)
reduced = tsne.fit_transform(normalized_embeddings[idx])

plt.figure(figsize=(10, 8))
plt.scatter(reduced[:, 0], reduced[:, 1], c=labels[idx], cmap="tab10", s=10)
plt.title("VAE Latent Space Clusters (t-SNE)")
plt.show()

# 2. Generated Images
print("\nGenerating new images from random latent vectors...")
with torch.no_grad():
    random_z = torch.randn(64, 32).to(device)
    generated_images = vae_model.decode(random_z).cpu()

fig, axes = plt.subplots(8, 8, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]})
for i, ax in enumerate(axes.flatten()):
    ax.imshow(generated_images[i].view(28, 28).numpy(), cmap='gray')
plt.suptitle("Generated Images from VAE")
plt.show()

# 3. Reconstruction Quality
print("\nVisualizing reconstruction quality...")
with torch.no_grad():
    original_images = next(iter(train_loader))[0][:16].to(device)
    reconstructed_images, _, _ = vae_model(original_images)
    reconstructed_images = reconstructed_images.cpu()

fig, axes = plt.subplots(4, 8, figsize=(10, 5), subplot_kw={'xticks':[], 'yticks':[]})
for i in range(16):
    axes[i // 8 * 2, i % 8].imshow(original_images[i].cpu().view(28, 28), cmap='gray')
    if i < 8: axes[0, i].set_title("Original", size=10)

    axes[i // 8 * 2 + 1, i % 8].imshow(reconstructed_images[i].view(28, 28), cmap='gray')
    if i < 8: axes[1, i].set_title("Reconstructed", size=10)
plt.suptitle("Original vs. Reconstructed Images")
plt.show()